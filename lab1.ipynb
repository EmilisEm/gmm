{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEWId/mFxqe93xN4xfxhhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c99db1b284e04fe1addcd1c5bdec50b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94d5f7fc21da47d5a8ca6a22c3d36844",
              "IPY_MODEL_f4d7ef167eec47228e4c1d950a815707"
            ],
            "layout": "IPY_MODEL_a70bd428dc1440008480b41e598b8c88"
          }
        },
        "94d5f7fc21da47d5a8ca6a22c3d36844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "Threshold:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c5b55d8c634d43bc8d0c2f2fbb91f970",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.01,
            "style": "IPY_MODEL_20ac9e5fa0a64c64a8764a32590447d2",
            "value": 0.21
          }
        },
        "f4d7ef167eec47228e4c1d950a815707": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_67795ab2b59046b2bca4ae071d659741",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\n",
                  "Results with threshold 0.21:\n",
                  "\n",
                  "Torch:\n",
                  "accuracy: 0.733\n",
                  "precision: 1.000\n",
                  "recall: 0.200\n",
                  "f1: 0.333\n",
                  "\n",
                  "Cello:\n",
                  "accuracy: 0.833\n",
                  "precision: 1.000\n",
                  "recall: 0.500\n",
                  "f1: 0.667\n",
                  "\n",
                  "Printer:\n",
                  "accuracy: 0.700\n",
                  "precision: 1.000\n",
                  "recall: 0.100\n",
                  "f1: 0.182\n"
                ]
              }
            ]
          }
        },
        "a70bd428dc1440008480b41e598b8c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b55d8c634d43bc8d0c2f2fbb91f970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ac9e5fa0a64c64a8764a32590447d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "67795ab2b59046b2bca4ae071d659741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilisEm/gmm/blob/master/lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Author LSP: 2213748\n",
        "\n",
        "#### Author: Emilis Kleinas\n",
        "\n",
        "#### Variant: Use of `ResNet` model with `Printer`, `Torch` and `Cello` classes\n",
        "\n",
        "#### What does the program do\n",
        "\n",
        "1. Downloads images for the specified classes from `OpenImages`\n",
        "2. Processes the images with the `ResNet` model\n",
        "3. Calculates precision, accuracy, recall and F1 statistics for the downloaded images\n"
      ],
      "metadata": {
        "id": "yYaEFqmBBu3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Mount google drive to access and store images"
      ],
      "metadata": {
        "id": "ixcPn7sTTPst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive_base_uri = '/content/drive'\n",
        "drive.mount(drive_base_uri)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX-ltkmqCGQo",
        "outputId": "fcefc238-74ee-4616-90ce-5242b0fdc0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import PIL.Image\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "p_SxTAJq_vW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The `data_dir` variable specifies the base directory to which the images will be saves.\n",
        "# The images are stored as follows `{data_dir}/{class_name}/images/*.jpg`\n",
        "# Where `class_name` is the name of the class being processed (e.g. \"cow\") in lowercase\n",
        "data_dir = drive_base_uri + \"/MyDrive/openimages\"\n",
        "number_of_images = 100\n",
        "classes = [\"Torch\", \"Cello\", \"Printer\"]"
      ],
      "metadata": {
        "id": "76zc9WqvCN5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download images for data classes (Optional if images already downloaded)"
      ],
      "metadata": {
        "id": "y88wDWSnTf-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openimages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpA6ddw3UpDT",
        "outputId": "26a99d15-da8b-4eef-cbc1-78b0a2efce67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openimages in /usr/local/lib/python3.11/dist-packages (0.0.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from openimages) (1.36.26)\n",
            "Requirement already satisfied: cvdata in /usr/local/lib/python3.11/dist-packages (from openimages) (0.0.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from openimages) (5.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openimages) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openimages) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openimages) (4.67.1)\n",
            "Requirement already satisfied: botocore<1.37.0,>=1.36.26 in /usr/local/lib/python3.11/dist-packages (from boto3->openimages) (1.36.26)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->openimages) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->openimages) (0.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openimages) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openimages.download import download_dataset\n",
        "download_dataset(data_dir, classes, limit=number_of_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP0yYieYJMHD",
        "outputId": "4b9c7744-4479-470f-a33b-868d158520c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.43it/s]\n",
            "100%|██████████| 10/10 [00:01<00:00,  7.12it/s]\n",
            "100%|██████████| 10/10 [00:01<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'torch': {'images_dir': '/content/drive/MyDrive/openimages/torch/images'},\n",
              " 'cello': {'images_dir': '/content/drive/MyDrive/openimages/cello/images'},\n",
              " 'printer': {'images_dir': '/content/drive/MyDrive/openimages/printer/images'}}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define custom `DataSet` class"
      ],
      "metadata": {
        "id": "kFkgdqL_ToAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, base_dir, transform):\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        for dataset_class in classes:\n",
        "            class_path = Path(data_dir) / dataset_class.lower() / \"images\"\n",
        "            if class_path.exists():\n",
        "                self.samples.extend([(str(p), dataset_class) for p in class_path.glob('*.jpg')])\n",
        "\n",
        "        print(f\"Found {len(self.samples)} images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, dataset_class = self.samples[idx]\n",
        "        try:\n",
        "            with PIL.Image.open(img_path) as img:\n",
        "                img = img.convert('RGB')\n",
        "                if self.transform:\n",
        "                    img = self.transform(img)\n",
        "                return img, 0, dataset_class\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "            return torch.zeros((3, 224, 224)), 0, dataset_class"
      ],
      "metadata": {
        "id": "V9vQHsjIE59c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize pretrained model `ResNet50`"
      ],
      "metadata": {
        "id": "Cwt8Fnr8Tw5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = ResNet50_Weights.DEFAULT\n",
        "model = resnet50(weights=weights)\n",
        "preprocess = weights.transforms()\n",
        "\n",
        "class_indices = {\n",
        "    class_name: weights.meta[\"categories\"].index(class_name.lower())\n",
        "    for class_name in classes\n",
        "  }\n",
        "\n",
        "print(\"Model initialized with class indices:\")\n",
        "for cls, idx in class_indices.items():\n",
        "    print(f\"{cls}: {idx}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sUPTrB9Fm3S",
        "outputId": "7630fed5-3b7d-46c4-8d43-fc33f54fc198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized with class indices:\n",
            "Torch: 862\n",
            "Cello: 486\n",
            "Printer: 742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize data loader"
      ],
      "metadata": {
        "id": "dRycwdLiZe9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(data_dir, transform=preprocess)\n",
        "data_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=1,\n",
        "    prefetch_factor=2,\n",
        "    persistent_workers=True,\n",
        "    multiprocessing_context='fork'\n",
        ")\n",
        "\n",
        "print(f\"Dataset size: {len(dataset)} images\")\n",
        "print(f\"Using {data_loader.num_workers} workers\")\n",
        "print(f\"Using GPU: {torch.cuda.is_available()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK5sy3R7Gdj7",
        "outputId": "dc2a1354-01a4-461c-a987-02528c069d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images\n",
            "Dataset size: 30 images\n",
            "Using 1 workers\n",
            "Using GPU: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply image batches to model and extraxt results\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "vjLop_iSZjOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = []\n",
        "all_true_classes = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_images, _, batch_classes in tqdm(data_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            batch_images = batch_images.cuda()\n",
        "            model = model.cuda()\n",
        "        predictions = model(batch_images).softmax(dim=1)\n",
        "        predictions = predictions.cpu()\n",
        "        all_predictions.append(predictions)\n",
        "        all_true_classes.extend(batch_classes)\n",
        "all_predictions = torch.cat(all_predictions, dim=0)\n",
        "\n",
        "results = {\n",
        "    'predictions': all_predictions,\n",
        "    'true_classes': all_true_classes,\n",
        "    'class_indices': class_indices\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpmncfbQGkCC",
        "outputId": "6cd1645c-e810-4035-92f1-51055b1b2057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:13<00:00, 13.40s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate metrics based on results returned by model"
      ],
      "metadata": {
        "id": "2u48G7trZrXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(threshold):\n",
        "    predictions = results['predictions']\n",
        "    true_classes = results['true_classes']\n",
        "    class_indices = results['class_indices']\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    for cls in classes:\n",
        "        idx = class_indices[cls]\n",
        "        pred_values = predictions[:, idx]\n",
        "        pred_binary = (pred_values > threshold)\n",
        "\n",
        "        is_current_class = torch.tensor([label == cls for label in true_classes])\n",
        "\n",
        "        tp = torch.sum((pred_binary) & (is_current_class)).float()\n",
        "        fp = torch.sum((pred_binary) & (~is_current_class)).float()\n",
        "        tn = torch.sum((~pred_binary) & (~is_current_class)).float()\n",
        "        fn = torch.sum((~pred_binary) & (is_current_class)).float()\n",
        "\n",
        "        total = float(len(true_classes))\n",
        "\n",
        "        precision = (tp / (tp + fp)).item() if (tp + fp) > 0 else 0\n",
        "        recall = (tp / (tp + fn)).item() if (tp + fn) > 0 else 0\n",
        "        accuracy = (tp + tn) / total\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        metrics[cls] = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "BlLL64EXHQcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "def update_threshold(threshold):\n",
        "    metrics = calculate_metrics(threshold)\n",
        "    print(f\"\\nResults with threshold {threshold}:\")\n",
        "\n",
        "    for cls, cls_metrics in metrics.items():\n",
        "        print(f\"\\n{cls.capitalize()}:\")\n",
        "        for metric, value in cls_metrics.items():\n",
        "            print(f\"{metric}: {value:.3f}\")\n",
        "\n",
        "threshold_slider = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0.0,\n",
        "    max=1.0,\n",
        "    step=0.01,\n",
        "    description=\"Threshold:\"\n",
        ")\n",
        "\n",
        "widgets.interactive(update_threshold, threshold=threshold_slider)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "c99db1b284e04fe1addcd1c5bdec50b3",
            "94d5f7fc21da47d5a8ca6a22c3d36844",
            "f4d7ef167eec47228e4c1d950a815707",
            "a70bd428dc1440008480b41e598b8c88",
            "c5b55d8c634d43bc8d0c2f2fbb91f970",
            "20ac9e5fa0a64c64a8764a32590447d2",
            "67795ab2b59046b2bca4ae071d659741"
          ]
        },
        "id": "LtUZR6z4HgW_",
        "outputId": "920049f2-dc85-479e-ad34-9458863b04f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(FloatSlider(value=0.5, description='Threshold:', max=1.0, step=0.01), Output()), _dom_cl…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c99db1b284e04fe1addcd1c5bdec50b3"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}